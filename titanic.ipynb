{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13b90b8",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import kaggle\n",
    "import zipfile\n",
    "\n",
    "DATASET_DIR = \"./dataset/titanic\"\n",
    "EXPORT_DIR = \"./dataset/preprocessed/titanic/\"\n",
    "\n",
    "if not os.path.exists(DATASET_DIR):\n",
    "    os.makedirs(DATASET_DIR)\n",
    "    kaggle.api.authenticate()\n",
    "    kaggle.api.competition_download_files(\"titanic\", path=DATASET_DIR)\n",
    "    with zipfile.ZipFile(os.path.join(DATASET_DIR, \"titanic.zip\"), \"r\") as zip_ref:\n",
    "        zip_ref.extractall(DATASET_DIR)\n",
    "    os.remove(os.path.join(DATASET_DIR, \"titanic.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd849f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (891, 12)\n",
      "Test Data Shape: (418, 11)\n",
      "Gender Submission Shape: (418, 2)\n",
      "\n",
      "Training Data Head:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "NaN Values in Training Data:\n",
      "Age         177\n",
      "Cabin       687\n",
      "Embarked      2\n",
      "dtype: int64\n",
      "\n",
      "Number of Unique Tickets in Training Data: 681\n",
      "Number of Unique Cabins in Training Data: 147\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATASET_DIR, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATASET_DIR, \"test.csv\"))\n",
    "gender_submission_df = pd.read_csv(os.path.join(DATASET_DIR, \"gender_submission.csv\"))\n",
    "\n",
    "print(\"Training Data Shape:\", train_df.shape)\n",
    "print(\"Test Data Shape:\", test_df.shape)\n",
    "print(\"Gender Submission Shape:\", gender_submission_df.shape)\n",
    "\n",
    "print(\"\\nTraining Data Head:\")\n",
    "print(train_df.head())\n",
    "\n",
    "nan_sum_per_col = train_df.isna().sum()\n",
    "print(\"\\nNaN Values in Training Data:\")\n",
    "print(nan_sum_per_col[nan_sum_per_col > 0])\n",
    "\n",
    "ticket_variety = train_df[\"Ticket\"].nunique()\n",
    "print(\"\\nNumber of Unique Tickets in Training Data:\", ticket_variety)\n",
    "\n",
    "cabin_variety = train_df[\"Cabin\"].nunique()\n",
    "print(\"Number of Unique Cabins in Training Data:\", cabin_variety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a261ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_double_quotes(df):\n",
    "    \"\"\"Remove double quotes from all string columns in the DataFrame.\"\"\"\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        df[col] = df[col].str.replace('\"', \"\", regex=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def combine_dataframes(a, b):\n",
    "    \"\"\"Combine two DataFrames on a specified key.\"\"\"\n",
    "    if \"Survived\" in a.columns:\n",
    "        return a\n",
    "    return pd.merge(a, b, on=\"PassengerId\", how=\"outer\")\n",
    "\n",
    "\n",
    "def drop_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Drop specified columns from the DataFrame.\"\"\"\n",
    "    COLS = [\"PassengerId\", \"Name\", \"Ticket\"]\n",
    "    return df.drop(columns=COLS, errors=\"ignore\")\n",
    "\n",
    "\n",
    "def cabin_to_alphabet(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Extract the first letter of the Cabin column.\"\"\"\n",
    "    df[\"Cabin\"] = df[\"Cabin\"].fillna(\"_\").str[0]\n",
    "    df[\"Cabin\"] = df[\"Cabin\"].replace(\"_\", \"NaN\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def one_hot_encoding(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    COLS = [\"Sex\", \"Embarked\", \"Cabin\"]\n",
    "    df = pd.get_dummies(df, columns=COLS, drop_first=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def connect_dataframes(a: pd.DataFrame, b: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Connect two DataFrames by concatenating them.\"\"\"\n",
    "    return pd.concat([a, b], ignore_index=True)\n",
    "\n",
    "\n",
    "def move_survived_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Move the 'Survived' column to the end of the DataFrame.\"\"\"\n",
    "    if \"Survived\" in df.columns:\n",
    "        cols = [col for col in df.columns if col != \"Survived\"]\n",
    "        cols.append(\"Survived\")\n",
    "        return df[cols]\n",
    "    return df\n",
    "\n",
    "\n",
    "def Survived_to_Category(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"Survived\"] = df[\"Survived\"].astype(\"category\")\n",
    "    df[\"Survived\"] = df[\"Survived\"].cat.rename_categories([\"Died\", \"Survived\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "test_df = combine_dataframes(test_df, gender_submission_df)\n",
    "train_df = connect_dataframes(train_df, test_df)\n",
    "\n",
    "train_df = drop_columns(train_df)\n",
    "train_df = remove_double_quotes(train_df)\n",
    "train_df = cabin_to_alphabet(train_df)\n",
    "\n",
    "train_df = one_hot_encoding(train_df)\n",
    "train_df = move_survived_column(train_df)\n",
    "\n",
    "train_df = Survived_to_Category(train_df)\n",
    "\n",
    "assert \"Survived\" in test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "290e1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "train_df.to_csv(os.path.join(EXPORT_DIR, 'train.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
